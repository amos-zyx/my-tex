@misc{muehlebach_accelerated_2023,
	title = {Accelerated First-Order Optimization under Nonlinear Constraints},
	doi = {10.48550/arXiv.2302.00316},
	abstract = {We exploit analogies between first-order algorithms for constrained optimization and non-smooth dynamical systems to design a new class of accelerated first-order algorithms for constrained optimization. Unlike Frank-Wolfe or projected gradients, these algorithms avoid optimization over the entire feasible set at each iteration. We prove convergence to stationary points even in a nonconvex setting and we derive rates for the convex setting. An important property of these algorithms is that constraints are expressed in terms of velocities instead of positions, which naturally leads to sparse, local and convex approximations of the feasible set (even if the feasible set is nonconvex). Thus, the complexity tends to grow mildly in the number of decision variables and in the number of constraints, which makes the algorithms suitable for machine learning applications. We apply our algorithms to a compressed sensing and a sparse regression problem, showing that we can treat nonconvex \${\textbackslash}ell{\textasciicircum}p\$ constraints (\$p{\textless}1\$) efficiently, while recovering state-of-the-art performance for \$p=1\$.},
	number = {{arXiv}:2302.00316},
	publisher = {{arXiv}},
	author = {Muehlebach, Michael and Jordan, Michael I.},
	date = {2023-02-01},
	eprinttype = {arxiv},
	eprint = {2302.00316 [cs, eess, math, stat]},
	keywords = {Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@misc{light_principle_2023,
	title = {The Principle of Optimality in Dynamic Programming: A Pedagogical Note},
	doi = {10.48550/arXiv.2302.08467},
	shorttitle = {The Principle of Optimality in Dynamic Programming},
	abstract = {The principle of optimality is a fundamental aspect of dynamic programming, which states that the optimal solution to a dynamic optimization problem can be found by combining the optimal solutions to its sub-problems. While this principle is generally applicable, it is often only taught for problems with finite or countable state spaces in order to sidestep measure theoretic complexities. Therefore, it cannot be applied to classic models such as inventory management and dynamic pricing models that has a continuous state spaces, and students may not be aware of the possible challenges involved in studying dynamic programming models with general state spaces. To address this, we provide conditions and a self-contained simple proof that establish when the principle of optimality for discounted dynamic programming is valid. These conditions shed light on the difficulties that may arise in the general state space case. We provide examples from the literature that include the relatively involved case of universally measurable dynamic programming and the simple case of finite dynamic programming where our main result can be applied to show that the principle of optimality holds.},
	number = {{arXiv}:2302.08467},
	publisher = {{arXiv}},
	author = {Light, Bar},
	date = {2023-02-16},
	eprinttype = {arxiv},
	eprint = {2302.08467 [math]},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability},
}
